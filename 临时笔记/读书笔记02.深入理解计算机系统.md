---
{}
---


## 编译系统

```
linux> gcc -o hello hello.c
```

GGG 编译器驱动程序读取源文件 hello.c，并把它翻译成一个可执行目标文件 hello。
这个翻译过程分为四个阶段：预处理器、编译器、汇编器、链接器。执行这四个阶段程序一起构成了编译系统。

![[编译系统.png]]

### 预处理器

预处理器（cpp）根据以字符 `#` 开头的命令，修改原始的C程序。
通常结果得到了另一个 C 程序，通常以 `*.i` 作为文件拓展名。

### 编译器

编译器（ccl）将文本文件 hello.i 翻译成文件文件 hello.s，它包含一个汇编语言程序

![[汇编语言程序.png]]

### 汇编器

汇编器（as）将 hello.s 翻译成机器语言指令，把这些指令打包成一种叫做**可重定位目标程序**的格式，并将结果保存在文件hello.o中。

### 链接器


## 系统的硬件组成

![[系统的硬件组成.png]]

### 总线

贯穿整个系统的是一组电子管道，称作总线，它携带信息字节并负责在各个部件间传递。

### I/O 设备

I/O（输入/输出）设备是系统与外部世界的联系通道。

每个I/O设备都通过一个控制器或适配器与I/O总线相连。

控制器与适配器的区别主要在于它们的封装方式。
控制器是 I/O 设备本身或者系统的主印制电路板（通常称作主板）上的芯片组。
适配器是一块插在主板槽上的卡。
两者的功能都是在I/O总线和I/O设备之间传递信息。

### 主存

主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。
物理上看，主存是由一组动态随机存储器（DRAM）芯片组成的。
逻辑上看，主存是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的。

### 处理器

中央处理单元（CPU），简称处理器，是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时候，PC都指向主存中的某条机器语言指令（即含有该指令地址）。

## 运行hello程序

### 从键盘上读取 hello 命令

![[运行hello程序.png]]
初始时，shell程序执行它的的指令，等待我们输入一个命令。当我们在键盘上输入字符串“./hello”后，shell程序将字符串逐一读入寄存器，在把它放入内存中。

### 从磁盘加载可执行文件到主存

![[从磁盘加载可执行文件到主存.png]]
当我们在键盘上敲回车键时，shell 程序就知道我们已经结束了命令的输入。然后shell 执行一系列指令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘中复制到主存。数据包括最终会被输出的字符串“hello，world\\n”。

利用 **直接存储器存取（DMA）** 技术，数据可以不通过处理器而直接从磁盘到主存。

### 将输出字符串从存储器写到显示器

![[将输出字符串从存储器写到显示器.png]]
一旦目标文件hello中的代码和数据被加载到主存，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将“hello，world\\n”字符串中的字节从主存复制到寄存器文件，在从寄存器文件中复制到显示设备，最终显示在屏幕上。

## 高速缓存存储器

![[高速缓存存储器.png]]

一个典型的寄存器文件只存储几百字节的信息，而主存可存放几十亿字节。然而处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。而随着半导体技术的进步，这种处理器与主存之间的差距还在持续增大。

针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为**高速缓存存储器（cache memory，简称 cache 或高速缓存）**，作为暂时的集结区域。存放处理器近期可能会需要的信息。

高速缓存集成在处理器芯片上。
L1高速缓存的容量可达数万字节，访问速度几乎和访问寄存器文件一样快。
L2高速缓存的容量为数十万到数百万，通过一条特殊的总线连接到处理器。
进程访问L2高速缓存的时间要比访问L1高速缓存的时间长5倍，但是仍然比访问主存的时间快5~10倍。
L1和L2高速缓存是一种叫做**静态随机访问存储器（SRAM）** 的硬件技术实现的。
系统可以获得一个很大的存储器，同时访问速度也很快，原因是利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能经常访问的数据，大部分内存操作都能在很快的高速缓存中完成。

- [java缓存(一)——高速缓存](https://www.jianshu.com/p/136077e3aacf)
- [java缓存(二)——虚拟存储器](https://www.jianshu.com/p/50968eabd71f)
- [并发编程-CPU缓存架构详解 & Disruptor的高性能设计方案](https://blog.csdn.net/weixin_43874650/article/details/134151771)
- [并发编程 -常用并发设计模式](https://blog.csdn.net/weixin_43874650/article/details/134109650?spm=1001.2014.3001.5502)
- [disruptor 史上最全 之1：**伪共享 原理&性能对比实战**](https://www.cnblogs.com/crazymakercircle/p/13909102.html)

## 存储器层次结构

![[存储器层次结构.png]]
存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。

## 操作系统管理硬件

![[计算机系统的分成视图.png]]
所有应用程序对硬件的操作尝试都必须通过操作系统。

![[操作系统提供的抽象表示.png]]
操作系统有两个基本功能：
1. 防止硬件被失控的应用程序滥用；
2. 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。
操作系统通过几个基本的抽象概念（进程、虚拟内容和文件）来实现这两个功能。

文件是对 I/O 设备的抽象表示；
虚拟内存是对 主存和磁盘 I/O 设备的抽象表示；
进程则是对处理器、主存和 I/O 设备的抽象表示。

### 进程

进程是操作系统对一个正在运行的程序的一种抽象。
并发运行：一个进程的指令和另一个进程的指令是交错执行的。
无论是单核系统还是多核系统中，一个CPU看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。
操作系统实现这种交错执行的机制称为上下文切换。

![[进程的上下文切换.png]]

**上下文**：操作系统保持跟踪进程运行所需的所有状态信息。例如，PC和寄存器文件的当前值。
**上下文切换**：当操作系统决定把控制权从当前进程转移到某个新进程时，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。

上图有两个并发的进程：shell 进程和 hello 进程。最开始，只有 shell 进程在运行，即等待命令行上的输入。当我们让它运行 hello 进程时，shell 进程通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统会保存 shell 进程的上下文，创建一个新的 hello 进程及其上下文，然后将控制权传给新的 hello 进程。hello 进程终止后，操作系统恢复 shell 进程的上下文，并将控制权传回给它，shell 进程会继续等待下一个命令的输入。

内核是什么？
从一个进程到另一个进程的转换是由系统内核(kernel)管理的。
内核是操作系统代码常驻主存的部分。
内核不是一个独立的进程，它是系统管理全部进程所用代码和数据结构的集合。

### 线程

一个进程可以由多个线程（执行单元）组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。

### 虚拟内存

虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占的使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。
![[虚拟地址空间.png]]
在 Linux 中，地址空间最上面的区域事保留给操作系统中的代码和数据的，这对所有进程来说都是一样的。地址空间的底部区域存放用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。

### 文件

文件就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看作是文件。系统中的所有输入输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。

## 系统间利用网络通信

网络也是一种 I/O 设备。

![[网络也是一种 IO 设备.png]]

### 客户端与服务端间交互的典型

![[客户端与服务端间交互的典型.png]]

### 并发和并行

并发：指一个同时具有多个活动的系统。
并行：用并发来使一个系统运行的更快。

#### 线程级并发

![[多核处理器组织结构.png]]
典型多核处理器的组织结构，芯片共有4个CPU核，每个核都有自己的 L1 和 L2 高速缓存，其中 L1 高速缓存分为两个部分（一个保存最近取到的命令，另一个存放数据）。

多处理器的使用可以从两方面提高系统性能：
1) 减少在执行多个任务时模拟并发的需要
2) 编写多线程并发程序

#### 指令级并行

在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为**指令级并行**。

流水线

超标量处理器：处理器可以达到比一个周期一条指令更快的执行效率。

#### 单指令、多数据并行

在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令可以产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。

### 计算机

#### 寻址和字节顺序

![[大端法和小端法.png]]

1. **大端法（Big-Endian）**：大端法是指数据的最高位字节（大端）存放在内存的最低位，也就是说，在地址最低的地方放置值的最高位字节（最重要的位）。例如，在32位整数0x12345678中，0x12是最高位字节，如果这个整数按照大端法存储，那么0x12会存储在最低的内存地址处。
2. **小端法（Little-Endian）**：小端法则相反，是将数据的最低位字节（小端）存放在内存的最低位。也就是说，在地址最低的地方放置值的最低位字节（最不重要的位）。按照同样的例子，32位整数0x12345678，按照小端法存储，0x78会存储在最低的内存地址处。

大端法与小端法的应用依赖于计算机系统硬件的设计，不同的硬件架构可能会采用不同的处理顺序。例如，Intel的x86架构是小端法，而IBM的PowerPC架构是大端法。混合者二者的系统被称为双端法或中立法。这个问题在跨平台数据交换中显得尤为重要，因为不同的系统可能需要进行端序的转换才能正确解读接收到的数据。